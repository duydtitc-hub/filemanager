# H∆∞·ªõng D·∫´n Ch·ªçn Model OpenAI

## üìä So S√°nh C√°c Model

| Model | Context Length | Max Output | Gi√° (1M tokens) | Khuy·∫øn ngh·ªã | Ghi ch√∫ |
|-------|---------------|------------|-----------------|-------------|---------|
| **gpt-4-turbo** | 128k | 16k | $10/$30 | ‚≠ê‚≠ê‚≠ê T·ªët nh·∫•t | L√Ω t∆∞·ªüng cho truy·ªán d√†i |
| **gpt-4o** | 128k | 16k | $5/$15 | ‚≠ê‚≠ê‚≠ê T·ªët nh·∫•t | Gi·ªëng turbo, r·∫ª h∆°n |
| **gpt-4o-mini** | 128k | 12k | $0.15/$0.6 | ‚≠ê‚≠ê T·ªët | R·∫•t r·∫ª, ch·∫•t l∆∞·ª£ng OK |
| **gpt-3.5-turbo-16k** | 16k | 4k | $0.5/$1.5 | ‚≠ê‚≠ê T·ªët | R·∫ª, ƒë·ªß cho truy·ªán ng·∫Øn |
| **gpt-4** | 8k | 6k | $30/$60 | ‚ö†Ô∏è KH√îNG khuy·∫øn ngh·ªã | Context nh·ªè, ƒë·∫Øt |

**Gi√°**: Input / Output (per 1M tokens)

## üéØ Khuy·∫øn Ngh·ªã Theo Nhu C·∫ßu

### ‚úÖ Truy·ªán 10.000 t·ª´ (Khuy·∫øn ngh·ªã)
```python
generator = StoryGenerator(model="gpt-4-turbo")
# HO·∫∂C
generator = StoryGenerator(model="gpt-4o")
```
- **∆Øu ƒëi·ªÉm**: Context l·ªõn (128k), ch·∫•t l∆∞·ª£ng cao, ·ªïn ƒë·ªãnh
- **Chi ph√≠**: ~$0.30-0.50 / truy·ªán

### üí∞ Ti·∫øt Ki·ªám Chi Ph√≠ (V·∫´n t·ªët)
```python
generator = StoryGenerator(model="gpt-4o-mini")
# HO·∫∂C
generator = StoryGenerator(model="gpt-3.5-turbo-16k")
```
- **∆Øu ƒëi·ªÉm**: R·∫•t r·∫ª (~$0.02-0.05 / truy·ªán)
- **Nh∆∞·ª£c ƒëi·ªÉm**: Ch·∫•t l∆∞·ª£ng kh√¥ng b·∫±ng GPT-4, c√≥ th·ªÉ thi·∫øu s√°ng t·∫°o

### ‚ùå TR√ÅNH D√πng
```python
generator = StoryGenerator(model="gpt-4")  # Context ch·ªâ 8k!
```
- **V·∫•n ƒë·ªÅ**: Context qu√° nh·ªè ‚Üí PH·∫¢I chia th√†nh nhi·ªÅu ch∆∞∆°ng ‚Üí m·∫•t m·∫°ch truy·ªán

## üîß C·∫•u H√¨nh Chi Ti·∫øt

### Model Config trong Code

```python
MODEL_CONFIGS = {
    "gpt-4": {
        "max_context": 8192,
        "safe_completion": 6000  # ƒê·ªÉ l·∫°i buffer cho prompt
    },
    "gpt-4-turbo": {
        "max_context": 128000,
        "safe_completion": 16000
    },
    "gpt-4o": {
        "max_context": 128000,
        "safe_completion": 16000
    },
    "gpt-4o-mini": {
        "max_context": 128000,
        "safe_completion": 12000
    },
    "gpt-3.5-turbo-16k": {
        "max_context": 16385,
        "safe_completion": 12000
    }
}
```

## üé® Ph∆∞∆°ng Ph√°p T·∫°o Truy·ªán

### C√°ch 1: Chia Th√†nh 5 Ch∆∞∆°ng (Hi·ªán t·∫°i)
```python
# Truy·ªán ƒë∆∞·ª£c t·∫°o qua 5 API calls ri√™ng bi·ªát:
# 1. M·ªü ƒë·∫ßu (~1000 t·ª´)
# 2. Ph√°t tri·ªÉn (~3000 t·ª´)
# 3. Cao tr√†o (~3000 t·ª´)
# 4. ƒê·ªânh ƒëi·ªÉm (~2000 t·ª´)
# 5. K·∫øt th√∫c (~1000 t·ª´)

result = generator.generate_horror_story()
```

**∆Øu ƒëi·ªÉm**:
- ‚úÖ Tr√°nh v∆∞·ª£t gi·ªõi h·∫°n token
- ‚úÖ Gi·ªØ ƒë∆∞·ª£c m·∫°ch truy·ªán qua conversation history
- ‚úÖ Ho·∫°t ƒë·ªông v·ªõi M·ªåI model

**Nh∆∞·ª£c ƒëi·ªÉm**:
- ‚ö†Ô∏è M·∫•t th·ªùi gian h∆°n (5 API calls)
- ‚ö†Ô∏è Chi ph√≠ cao h∆°n (~5x)

### C√°ch 2: T·∫°o 1 L·∫ßn (Ch·ªâ cho model l·ªõn)
N·∫øu d√πng `gpt-4-turbo` ho·∫∑c `gpt-4o`, c√≥ th·ªÉ t·∫°o 1 l·∫ßn:

```python
# C·∫ßn s·ª≠a code ƒë·ªÉ kh√¥ng chia ch∆∞∆°ng
# (Hi·ªán t·∫°i ch∆∞a implement)
```

## üí° Tips Ti·∫øt Ki·ªám Chi Ph√≠

1. **D√πng model nh·ªè cho test**:
   ```python
   # Test v·ªõi gpt-4o-mini tr∆∞·ªõc
   test_result = create_horror_story(model="gpt-4o-mini")
   
   # Satisfied? T·∫°o b·∫£n final v·ªõi gpt-4-turbo
   final_result = create_horror_story(model="gpt-4-turbo")
   ```

2. **Gi·∫£m temperature cho k·∫øt qu·∫£ ·ªïn ƒë·ªãnh h∆°n**:
   ```python
   result = generator.generate_horror_story(temperature=0.7)
   # Thay v√¨ 0.85 (√≠t random h∆°n = √≠t c·∫ßn retry)
   ```

3. **Cache k·∫øt qu·∫£ t·ªët**:
   - File ƒë√£ l∆∞u trong `stories/`
   - D√πng l·∫°i thay v√¨ t·∫°o m·ªõi

## üìà ∆Ø·ªõc T√≠nh Chi Ph√≠

### Truy·ªán 10.000 t·ª´ (~15.000 tokens output)

| Model | Input Tokens | Output Tokens | Chi ph√≠ | Th·ªùi gian |
|-------|--------------|---------------|---------|-----------|
| gpt-4-turbo | ~6k | ~15k | $0.51 | 3-5 ph√∫t |
| gpt-4o | ~6k | ~15k | $0.26 | 3-5 ph√∫t |
| gpt-4o-mini | ~6k | ~15k | $0.01 | 2-4 ph√∫t |
| gpt-3.5-turbo-16k | ~6k | ~12k* | $0.02 | 2-3 ph√∫t |

*Output gi·ªõi h·∫°n ·ªü 12k tokens

### Batch 10 Truy·ªán

| Model | Chi ph√≠ | Khuy·∫øn ngh·ªã |
|-------|---------|-------------|
| gpt-4o-mini | ~$0.10 | ‚≠ê‚≠ê‚≠ê T·ªët nh·∫•t cho batch |
| gpt-3.5-turbo-16k | ~$0.20 | ‚≠ê‚≠ê T·ªët |
| gpt-4o | ~$2.60 | ‚≠ê OK n·∫øu c·∫ßn ch·∫•t l∆∞·ª£ng |
| gpt-4-turbo | ~$5.10 | ‚ö†Ô∏è ƒê·∫Øt |

## üîç Ki·ªÉm Tra Model Hi·ªán T·∫°i

```python
from story_generator import StoryGenerator

gen = StoryGenerator(model="gpt-4-turbo")
print(f"Model: {gen.model}")
print(f"Max tokens: {gen.max_completion_tokens}")
```

## üÜò Troubleshooting

### L·ªói: "context_length_exceeded"
```
This model's maximum context length is 8192 tokens. 
However, you requested 17197 tokens...
```

**Gi·∫£i ph√°p**:
1. ‚úÖ ƒê·ªïi sang model l·ªõn h∆°n: `gpt-4-turbo` ho·∫∑c `gpt-4o`
2. ‚úÖ Code ƒë√£ t·ª± ƒë·ªông chia ch∆∞∆°ng (kh√¥ng c·∫ßn s·ª≠a g√¨)
3. ‚ùå KH√îNG d√πng `gpt-4` (context nh·ªè)

### Truy·ªán Qu√° Ng·∫Øn
- TƒÉng `max_tokens` (n·∫øu model cho ph√©p)
- Th√™m y√™u c·∫ßu c·ª• th·ªÉ v·ªÅ ƒë·ªô d√†i trong `custom_requirements`

### Truy·ªán M·∫•t M·∫°ch
- Gi·∫£m `temperature` (0.6-0.7)
- D√πng model t·ªët h∆°n (`gpt-4-turbo` thay v√¨ `gpt-3.5`)

## üìû Li√™n H·ªá / Issues

N·∫øu v·∫´n g·∫∑p v·∫•n ƒë·ªÅ, ki·ªÉm tra:
1. API key h·ª£p l·ªá
2. ƒê·ªß credit trong account OpenAI
3. Model name ƒë√∫ng (xem danh s√°ch tr√™n)

---

**Khuy·∫øn ngh·ªã cu·ªëi c√πng**: D√πng **`gpt-4o`** - c√¢n b·∫±ng gi·ªØa gi√° v√† ch·∫•t l∆∞·ª£ng! üéØ
